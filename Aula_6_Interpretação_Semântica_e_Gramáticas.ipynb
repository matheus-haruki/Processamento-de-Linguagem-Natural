{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHAnPh7wOxpgLYXq5di73L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matheus-haruki/Processamento-de-Linguagem-Natural/blob/main/Aula_6_Interpreta%C3%A7%C3%A3o_Sem%C3%A2ntica_e_Gram%C3%A1ticas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo do notebook:\n",
        "\n",
        "O objetivo deste notebook é apresentar, de forma prática e didática, diferentes abordagens para representar e interpretar o significado de palavras e frases na linguagem natural, com foco em técnicas de interpretação semântica e análise gramatical. Através de exemplos implementados em Python, o notebook demonstra como a semântica pode ser tratada computacionalmente por meio de:\n",
        "\n",
        "- Redes semânticas, que organizam o conhecimento com base em relações entre palavras;\n",
        "\n",
        "- Embeddings, que traduzem palavras em vetores numéricos e permitem medir similaridade semântica;\n",
        "\n",
        "- Árvores sintáticas, que revelam as estruturas gramaticais e dependências entre termos em uma frase;\n",
        "\n",
        "- Ontologias, que representam formalmente conceitos e suas hierarquias em domínios específicos.\n",
        "\n",
        "Além disso, o notebook introduz um estudo de caso que aplica essas técnicas em um corpus textual, permitindo analisar o significado de palavras em contexto e explorar como o PLN pode ser utilizado em tarefas mais avançadas, como extração de conhecimento e compreensão de texto.\n",
        "\n",
        "Técnicas de PLN implementadas:\n",
        "\n",
        "1. Redes Semânticas com WordNet (NLTK)\n",
        "  - Uso do wordnet com suporte ao idioma português.\n",
        "\n",
        "  - Busca de sinônimos com wordnet.synsets(\"carro\", lang=\"por\").\n",
        "\n",
        "  - Interpretação semântica baseada em conjuntos de sinônimos (synsets).\n",
        "\n",
        "2. Embeddings e Similaridade Semântica (spaCy)\n",
        "  - Carregamento do modelo pt_core_news_md do spaCy.\n",
        "\n",
        "  - Cálculo de similaridade semântica entre palavras, ex: \"rei\" e \"rainha\" usando .similarity().\n",
        "\n",
        "3. Análise Sintática com Árvore de Dependência (spaCy)\n",
        "  - Uso de pt_core_news_sm do spaCy.\n",
        "\n",
        "  - Geração de árvore sintática com displacy.render() para visualizar dependências gramaticais em frases.\n",
        "\n",
        "4. Ontologias com Owlready2\n",
        "Criação de uma ontologia simples com classes como Animal, Mamifero, Cachorro, e Gato.\n",
        "\n",
        "  - Armazenamento da ontologia em formato OWL.\n",
        "\n",
        "  - Apoio à organização semântica do conhecimento.\n",
        "\n",
        "5. Estudo de Caso - Análise Semântica em Corpus\n",
        "  - Embora cortado no trecho analisado, começa a usar bibliotecas como spacy, nltk e pandas.\n",
        "\n",
        "  - Provavelmente envolve aplicação de técnicas anteriores em um conjunto de dados real."
      ],
      "metadata": {
        "id": "Iqs_aimE-mwQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo 01 - Representação do significado das palavras e frases com redes Semânticas."
      ],
      "metadata": {
        "id": "oTQFht74jfN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')\n",
        "# banco de dados para utilização do sinônimos\n",
        "nltk.download('omw-1.4')\n",
        "# Corpus que relaciona as palavras em diversos idiomas - tradução automática\n",
        "\n",
        "# Método para encontrar os sinônimos da palavras indicada e o idioma\n",
        "sinonimos = wordnet.synsets(\"carro\", lang=\"por\")\n",
        "\n",
        "print(sinonimos) # imprimi a lista gerada\n",
        "\n",
        "for s in sinonimos:\n",
        "    print(s.lemmas()[0].name()) # Mostra sinônimos da palavra\n",
        "# s. lemmas(): Obtém a lista de lemmas (formas básicas das palavras) no synset atual.\n",
        "# [0]: Pega o primeiro lemma da lista.\n",
        "# name(): Obtém o nome do lemma (o sinônimo em si).\n",
        "# print(): Imprime o sinônimo na tela.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byQwIIfVjg0M",
        "outputId": "651a6c0e-ef69-48da-bc32-a72efa434049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Synset('beach_wagon.n.01'), Synset('car.n.01'), Synset('car.n.02'), Synset('cart.n.01')]\n",
            "beach_wagon\n",
            "car\n",
            "car\n",
            "cart\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo 02 - Representação do significado das palavras e frases por\n",
        "Vetores (embeddings)."
      ],
      "metadata": {
        "id": "xmr_5A_VkMYN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_md"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XKsjLGUkNJZ",
        "outputId": "c7edd956-865f-4b31-d707-f4a3f4ce3678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_md-3.8.0/pt_core_news_md-3.8.0-py3-none-any.whl (42.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-md\n",
            "Successfully installed pt-core-news-md-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Carregando o modelo pre treinado - modelo com relações entre palavras\n",
        "nlp = spacy.load('pt_core_news_md')\n",
        "# criação de objetos, com suas informações e vetores\n",
        "palavral = nlp('rei')\n",
        "palavra2 = nlp('rainha')\n",
        "# Calculo de similaridade dos objetos vetorizadas\n",
        "print(palavral.similarity(palavra2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj6gCgiEkWEg",
        "outputId": "ad95bab0-1744-4058-df2c-88cffd6c9605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6001228094100952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo 03 - Árvore Sintática"
      ],
      "metadata": {
        "id": "XIrEjkPilbsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR_WeEL7lcaS",
        "outputId": "b2900aa7-9227-4f38-c1b8-782500609e1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "# módulo para visualização de dependencias\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")\n",
        "frase = \"O cachorro correu no parque.\"\n",
        "doc = nlp(frase)\n",
        "\n",
        "displacy.render(doc, style='dep', jupyter=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "nCZOsRiTllQc",
        "outputId": "d43b9801-c882-4223-9ec5-df588097b822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"5e107deba4dc45869a720c942f3ed67a-0\" class=\"displacy\" width=\"925\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">O</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cachorro</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">correu</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">no</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">parque.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5e107deba4dc45869a720c942f3ed67a-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5e107deba4dc45869a720c942f3ed67a-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5e107deba4dc45869a720c942f3ed67a-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5e107deba4dc45869a720c942f3ed67a-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5e107deba4dc45869a720c942f3ed67a-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5e107deba4dc45869a720c942f3ed67a-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-5e107deba4dc45869a720c942f3ed67a-0-3\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-5e107deba4dc45869a720c942f3ed67a-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M750.0,179.0 L758.0,167.0 742.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exemplo 04 - Ontologia"
      ],
      "metadata": {
        "id": "Q6w1IeUUlnKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install owlready2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feXwx4z6l3Ki",
        "outputId": "6cb993fd-4a3d-4582-8bf0-6c975b6ae5c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting owlready2\n",
            "  Downloading owlready2-0.47.tar.gz (27.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/27.3 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: owlready2\n",
            "  Building wheel for owlready2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for owlready2: filename=owlready2-0.47-cp311-cp311-linux_x86_64.whl size=24577500 sha256=52209195c4ec9f6fe56919356495b03adcb0d27bafe80f78bfc55e34cb8fcfb2\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/9a/a3/fb1ac6339caa859c8bb18d685736168b0b51d851af13d81d52\n",
            "Successfully built owlready2\n",
            "Installing collected packages: owlready2\n",
            "Successfully installed owlready2-0.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from owlready2 import *\n",
        "\n",
        "# Criando uma nova ontologia\n",
        "onto = get_ontology(\"http://exemplo.com/minha_ontologia.owl\")\n",
        "\n",
        "with onto:\n",
        "    class Animal(Thing): pass\n",
        "    class Mamifero(Animal): pass\n",
        "    class Cachorro(Mamifero): pass\n",
        "    class Gato(Mamifero): pass\n",
        "\n",
        "onto.save(\"minha_ontologia.owl\")\n"
      ],
      "metadata": {
        "id": "i4wyDGBYmEoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SETJnjwAmPl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estudo de Caso 01 - Aplicação de Análise Semântica em um corpus"
      ],
      "metadata": {
        "id": "b3fty9RrmU9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import spacy\n",
        "import nltk\n",
        "import pandas as pd\n",
        "\n",
        "from nltk.corpus import wordnet as wn\n",
        "# banco de dados léxico - agrupa palavras em conjuntos de sinônimos\n"
      ],
      "metadata": {
        "id": "4LN52cSJnU1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Acessar funcionalidades como tokenização, análise sintática e vetores de palavras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5tjQrRLnado",
        "outputId": "bd9fb8fc-6dc6-4f04-e48d-8e1e29761369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Carregar o modelo pré-treinado do spaCy (idioma inglês)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Acessar funcionalidades como tokenização, análise sintática e vetores de palavras\n",
        "\n",
        "# Texto de exemplo\n",
        "texto = \"Barack Obama was the president of the United States and was born in Hawaii.\"\n",
        "\n",
        "# Processar o texto\n",
        "doc = nlp(texto)\n",
        "\n",
        "# 2. Reconhecimento de Entidades Nomeadas (NER)\n",
        "entities_data = []\n",
        "\n",
        "for ent in doc.ents:\n",
        "    entities_data.append({\n",
        "        \"Entidade\": ent.text,\n",
        "        \"Tipo\": ent.label_\n",
        "    })\n",
        "\n",
        "# Convertendo para DataFrame\n",
        "df_entities = pd.DataFrame(entities_data)\n",
        "print(\"\\n Reconhecimento de Entidades:\")\n",
        "print(df_entities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lg4D7P5nrNw",
        "outputId": "996f31ff-56a5-408a-f532-ea30ce3ce82f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Reconhecimento de Entidades:\n",
            "            Entidade    Tipo\n",
            "0       Barack Obama  PERSON\n",
            "1  the United States     GPE\n",
            "2             Hawaii     GPE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Análise Semântica com WordNet\n",
        "semantic_data = []\n",
        "\n",
        "for token in doc:\n",
        "    synsets = wn.synsets(token.text)\n",
        "    if synsets:\n",
        "        semantic_data.append({\n",
        "            \"Palavra\": token.text,\n",
        "            \"Significado\": synsets[0].definition(),\n",
        "            \"Exemplo\": synsets[0].examples()\n",
        "        })\n",
        "\n",
        "# Convertendo para DataFrame\n",
        "df_semantic = pd.DataFrame(semantic_data)\n",
        "print(\"\\n Análise Semântica:\")\n",
        "print(df_semantic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO1HOgEBn9uf",
        "outputId": "fc2fdd3c-f200-4197-a496-5b8e768056b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Análise Semântica:\n",
            "     Palavra                                        Significado  \\\n",
            "0        was  a state in northwestern United States on the P...   \n",
            "1  president      an executive officer of a firm or corporation   \n",
            "2     United  act in concert or unite in a common purpose or...   \n",
            "3     States  the territory occupied by one of the constitue...   \n",
            "4        was  a state in northwestern United States on the P...   \n",
            "5       born  British nuclear physicist (born in Germany) ho...   \n",
            "6         in    a unit of length equal to one twelfth of a foot   \n",
            "7     Hawaii  a state in the United States in the central Pa...   \n",
            "\n",
            "                            Exemplo  \n",
            "0                                []  \n",
            "1                                []  \n",
            "2                                []  \n",
            "3  [his state is in the deep south]  \n",
            "4                                []  \n",
            "5                                []  \n",
            "6                                []  \n",
            "7                                []  \n"
          ]
        }
      ]
    }
  ]
}